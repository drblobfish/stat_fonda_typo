[
  {
    "objectID": "index.html#organisation",
    "href": "index.html#organisation",
    "title": "Statistiques Fondamentales",
    "section": "Organisation",
    "text": "Organisation\n\nLes CM ont lieu les jeudi à (8h30 - 10h30), et les vendredi (10h45 - 12h45) sauf le premier cours qui a lieu lundi 8 janvier à 10h45-12h45.\nLes TD ont lieu lundi (13h45 - 16h45) et vendredi (13h30 - 15h30), de lundi 8 janvier à vendredi 16 février.\nIl y aura deux contrôles de 2h, le vendredi 26 janvier et lundi 12 février.\nL’examen a lieu le 1er mars de 13h30 à 16h30.\nIl y aura une interro de 5 minutes chaque semaine le jeudi."
  },
  {
    "objectID": "index.html#utiliser-ce-site",
    "href": "index.html#utiliser-ce-site",
    "title": "Statistiques Fondamentales",
    "section": "Utiliser ce site",
    "text": "Utiliser ce site\nChaque chapitre de ce livre contient une page dédiée au cours théorique, une page dédiée à quelques exemples, et une feuille d’exercices.\nLa saveur du cours est essentiellement mathématique et nous n’aurons pas de TP d’info ; cependant, je vous recommande vraiment d’essayer d’appliquer tout ça via votre langage de programmation favori, c’est-à-dire Python R SAS C++ Julia. J’essaierai autant que possible de fournir des mini-jeux de données avec des petits challenges pour appliquer ce que vous apprenez en cours.\nCes notes sont mises en lignes et totalement accessibles via Quarto. Si vous savez comment utiliser git, n’hésitez pas à corriger toutes les erreurs que vous pourriez voir (et Dieu sait qu’elles seront nombreuses) via des pull requests."
  },
  {
    "objectID": "ch1.html#un-modèle-jouet",
    "href": "ch1.html#un-modèle-jouet",
    "title": "1  Introduction",
    "section": "1.1 Un modèle-jouet",
    "text": "1.1 Un modèle-jouet"
  },
  {
    "objectID": "ch1.html#quest-ce-quun-problème-statistique",
    "href": "ch1.html#quest-ce-quun-problème-statistique",
    "title": "1  Introduction",
    "section": "1.2 Qu’est-ce qu’un problème statistique ?",
    "text": "1.2 Qu’est-ce qu’un problème statistique ?\nIl n’y aurait pas de statistiques s’il n’y avait pas de monde réel, et comme chacun sait, le monde réel est principalement composé de quantités aléatoires.\nUn problème statistique tire donc toujours sa source d’un ensemble d’observations, disons \\(n\\) observations notées \\(x_1, \\dotsc, x_n\\) ; cet ensemble d’observations est appelé un échantillon. L’hypothèse de base de tout travail statistique consiste à supposer que cet échantillon suit une certaine loi de probabilité ; l’objectif est de trouver laquelle. Évidemment, on ne va pas partir de rien : il faut bien faire des hypothèse minimales sur cette loi. Ce qu’on appelle un modèle statistique est le choix d’une famille de lois de probabilités que l’on suppose pertinentes.\n\nDéfinition 1.1 Formellement, choisir un modèle statistique revient à choisir trois choses : \n\n\\(\\mathcal{X}\\), l’espace dans lequel vit notre échantillon ; \n\\(\\mathscr{F}\\), une tribu sur \\(\\mathcal{X}\\), pour donner du sens à ce qui est observable ou non ;\n\\((P_\\theta)_{\\theta \\in \\Theta}\\), une famille de mesures de probabilités sur \\(\\mathcal{X}\\) indexée par \\(\\theta \\in \\Theta\\), où \\(\\Theta\\) est appelé espace des paramètres.\n\n\nEn pratique, dans ce cours, on aura toujours un échantillon \\((x_1, \\dotsc, x_n)\\) où les \\(x_i\\) vivent dans un même espace, disons \\(\\mathbb{R}^d\\) pour simplifier. On devrait donc écrire \\(\\mathcal{X} = \\mathbb{R}^{d\\times n}\\) ; et l’on fera toujours l’hypothèse que ces observations sont indépendantes les unes des autres, et que ces observations ont la même loi de probabilité. Autrement dit, on se donnera toujours une mesure \\(\\mu_\\theta\\) sur \\(\\mathbb{R}^d\\) et on supposera que la loi de notre échantillon est \\(P_\\theta = \\mu_\\theta^{\\otimes n}\\). Dans ce cadre, les observations \\(x_i\\) sont des réalisations de variables aléatoires iid de loi \\(\\mu_\\theta\\).\n\nDéfinition 1.2 On dit qu’un modèle statistique est identifiable si \\(\\theta \\neq \\theta'\\) entraîne \\(P_\\theta \\neq P_{\\theta'}\\).\n\nSi l’on a bien choisi notre modèle statistique, alors il existe un « vrai » paramètre, disons \\(\\theta_\\star\\), tel que les observations \\(x_1, \\dotsc, x_n\\) sont des réalisations de loi \\(\\mu_{\\theta_\\star}\\). L’objectif est alors de trouver \\(\\theta_\\star\\) ou quelque information que ce soit le concernant.\nDans un modèle (identifiable), la statistique inférentielle (classique) permet de faire trois choses:\n\nTrouver une valeur approchée du vrai paramètre \\(\\theta_\\star\\) (estimation ponctuelle).\nDonner une zone de \\(\\Theta\\) dans laquelle le vrai paramètre \\(\\theta_\\star\\) a des chances de se trouver (intervalle de confiance).\nRépondre à des questions binaires sur \\(\\theta_\\star\\), par exemple « \\(\\theta_\\star\\) est-il positif ? »."
  },
  {
    "objectID": "ch1.html#quest-ce-quun-estimateur",
    "href": "ch1.html#quest-ce-quun-estimateur",
    "title": "1  Introduction",
    "section": "1.3 Qu’est-ce qu’un estimateur ?",
    "text": "1.3 Qu’est-ce qu’un estimateur ?\n\nDéfinition 1.3 Une statistique est une fonction mesurable des observations. Plus formellement, si le modèle statistique fixé est \\((\\mathcal{X}, \\mathscr{F}, P)\\), alors une statistique est n’importe quelle fonction mesurable de \\((\\mathcal{X}, \\mathscr{F})\\).\n\nLe point important est qu’une statistique ne peut pas prendre \\(\\theta\\) en argument. Ses valeurs ne doivent dépendre du paramètre \\(\\theta\\) qu’au travers de \\(P_\\theta\\).\nSi \\(X\\) est une variable aléatoire et \\(T\\) une statistique, alors \\(T(X)\\) est une variable aléatoire. On peut donc définir des quantités théoriques liées à \\(T\\): typiquement, si \\(X\\) a pour loi \\(P_\\theta\\), on peut définir la valeur moyenne de \\(T\\) sous le modèle \\(P_\\theta\\) comme \\[\\mathbb{E}_\\theta[T(X)] = \\int_{\\mathcal{X}} T(x) P_\\theta(dx)\\] ou encore sa variance \\(\\mathbb{E}_\\theta[\\mathsf{t}(X)^2] - (\\mathbb{E}_\\theta[\\mathsf{t}(X)])^2\\), etc. On peut aussi calculer la valeur de cette statistique sur l’échantillon dont on dispose, c’est-à-dire \\(\\mathsf{t}(x_1, \\dotsc, x_n)\\). Ce qui ne se voit pas dans la définition, c’est qu’une bonne statistique devrait être facilement calculable ; à la place de statistique, on peut penser à algorithme : une bonne statistique doit pouvoir être calculée facilement par un algorithme ne prenant en entrée que les échantillons \\(x_i\\).\nSi le but est de deviner la valeur de \\(\\theta\\) à partir des observations, il est naturel de considérer des statistiques à valeurs dans \\(\\Theta\\). C’est précisément la définition d’un estimateur.\n\nDéfinition 1.4 Dans le modèle \\((\\mathcal{X},\\mathcal{A}, (P_\\theta)_{\\theta \\in \\Theta})\\), un estimateur de \\(\\theta\\) est une statistique à valeurs dans \\(\\Theta\\).\n\nEn fait, on n’est pas obligés de vouloir estimer précisément \\(\\theta\\). Peut-être qu’on veut estimer quelque chose qui dépend de \\(\\theta\\), mais qui n’est pas \\(\\theta\\) ; disons, une fonction \\(q(\\theta)\\). Dans ce cas, un estimateur de \\(q(\\theta)\\) sera simplement une statistique à valeurs dans l’espace où vit \\(q(\\theta)\\)."
  },
  {
    "objectID": "ch1.html#non-paramétrique",
    "href": "ch1.html#non-paramétrique",
    "title": "1  Introduction",
    "section": "1.4 Non-paramétrique",
    "text": "1.4 Non-paramétrique\nTraditionnellement, on distingue deux grands types de modèles : on dit qu’un modèle est paramétrique lorsque le paramètre \\(\\theta\\) vit dans un espace de dimension finie (autrement dit quand \\(\\Theta\\) est une partie de \\(\\mathbb{R}^d\\)), et sinon on dit que le modèle est non-paramétrique. On verra quelques idées d’estimation non-paramétrique dans le dernier chapitre du cours."
  },
  {
    "objectID": "ch2.html#précision-dun-estimateur",
    "href": "ch2.html#précision-dun-estimateur",
    "title": "2  Estimation de paramètre",
    "section": "2.1 Précision d’un estimateur",
    "text": "2.1 Précision d’un estimateur\nOn a fixé un modèle statistique \\((\\mathcal{X}, \\mathscr{F}, (P_\\theta))\\), et l’on cherche à estimer \\(\\theta\\).\n\nDéfinition 2.1 Le biais de \\(\\hat{\\theta}\\) est la quantité \\(\\mathbb{E}_\\theta[\\hat\\theta - \\theta]\\). L’estimateur est dit sans biais s’il est de biais nul.\n\n\nDéfinition 2.2 Le risque quadratique de \\(\\hat\\theta\\) est la quantité \\(\\mathbb{E}_{\\theta}[ |\\hat{\\theta}- \\theta|^2]\\).\n\nEn pratique, on peut vouloir estimer non pas \\(\\theta\\) lui-même, mais un paramètre \\(\\psi = \\psi_\\theta\\) qui dépend de \\(\\theta\\), comme \\(\\cos(\\theta)\\) ou \\(|\\theta|\\) par exemple. Dans ce cas, si \\(\\hat{\\psi}\\) est un estimateur de \\(\\psi\\) alors le biais est défini par \\(\\mathbb{E}_\\theta[\\hat{\\psi} - \\psi_\\theta]\\) et le risque quadratique par \\(\\mathbb{E}_\\theta [ |\\psi^2 - \\psi_\\theta|^2]\\).\n\nThéorème 2.1 \\[\n\\mathbb{E}_{\\theta} [|\\hat{\\theta}-\\theta|^2]\n= \\underbrace{\\operatorname{Var}_{\\theta} (\\hat{\\theta})}_{\\text{variance}} +\n\\underbrace{\\left(\\mathbb{E}_{\\theta}[\\hat{\\theta}]-\\theta \\right)^2}_{\\text{carré du biais}} \\, .\n\\]\n\nLa dépendance du risque quadratique vis à vis de la taille de l’échantillon est une question importante en statistique mathématique. Elle concerne la vitesse d’estimation (pour une suite d’expériences donnée, quelles sont les meilleures vitesses envisageables, et comment les obtenir ?).\nPour introduire la notion de consistance d’une suite d’estimateurs, nous aurons besoin des notions de convergence en probabilité et de convergence presque sûre.\n\nDéfinition 2.3 Une suite de variables aléatoires \\(X_n\\) à valeurs dans \\(\\mathbb{R}^k\\) converge en probabilité vers une variable aléatoire \\(X\\) à valeurs dans \\(\\mathbb{R}^k\\), vivant sur cet espace probabilisé si et seulement si, pour tout \\(\\epsilon &gt;0\\) \\[\n\\lim_{n\\to\\infty} \\mathbb{P} (| X_n -X|&gt; \\epsilon ) = 0 \\, .\n\\]\n\n\nDéfinition 2.4 (consistance d’un estimateur) Une suite d’estimateurs \\((\\widehat{\\theta}_n)\\) est consistante pour l’estimation de \\(\\theta\\) lorsque pour n’importe quel \\(\\theta \\in \\Theta\\), si \\[ \\forall \\varepsilon&gt;0, \\qquad \\lim_n     P_\\theta ( | \\widehat{\\theta}_n-\\theta| &gt; \\varepsilon ) =0 \\qquad\\text{(convergence en probabilité).}\n\\] La suite est fortement consistante si pour n’importe quel \\(\\theta \\in \\Theta\\), \\[\n\\hat{\\theta}_n \\to \\theta \\quad P_\\theta-\\text{p.s.} \\qquad\\text{(convergence presque sûre).}\n\\]"
  },
  {
    "objectID": "ch2.html#normalité-asymptotique",
    "href": "ch2.html#normalité-asymptotique",
    "title": "2  Estimation de paramètre",
    "section": "2.2 Normalité asymptotique",
    "text": "2.2 Normalité asymptotique\n\nDéfinition 2.5 (normalité asymtotique) Soit \\(\\theta\\) un paramètre à estimer, et \\(\\hat{\\theta}_n\\) une suite d’estimateurs de \\(\\theta\\). On dit que ces estimateurs sont asymptotiquement gaussiens (ou normaux) si, après les avoir renormalisés convenablement, ils convergent en loi vers une loi gaussienne. Autrement dit, s’il existe une suite \\(a_n\\) de nombres réels tels que \\[ a_n(\\hat{\\theta}_n - \\theta) \\xrightarrow[n\\to \\infty]{\\text{loi}} N(0,\\Sigma)\\] où \\(\\Sigma\\) est une matrice de covariance qui dépend peut-être de \\(\\theta\\) — pour éviter les cas dégénérés, on demande à ce que \\(\\Sigma\\) soit non-nulle.\n\nLa normalité asymptotique n’est pas intéressante en elle-même, l’idée est de chercher le comportement asymptotique de la statistique recentrée pour pouvoir en déduire des garanties en terme de risque asymptotique ou d’intervalle de confiance. Le théorème central limite indique que le comportement asymptotique normal est relativement fréquent."
  },
  {
    "objectID": "ch2.html#deux-outils-sur-la-normalité-asymptotique",
    "href": "ch2.html#deux-outils-sur-la-normalité-asymptotique",
    "title": "2  Estimation de paramètre",
    "section": "2.3 Deux outils sur la normalité asymptotique",
    "text": "2.3 Deux outils sur la normalité asymptotique\n\nThéorème 2.2 (Lemme de Slutsky) Soit \\((X_n)\\) une suite de variables aléatoire qui converge en loi vers \\(X\\) et \\((Y_n)\\) une suite de variables aléatoires qui converge en probabilité (ou en loi) vers une constante \\(c\\). Alors, le couple \\((X_n, Y_n)\\) converge en loi vers \\((X,c)\\) ; autrement dit, pour toute fonction continue bornée \\(\\varphi\\), \\[\\mathbb{E}[\\varphi(X_n, Y_n)] \\to \\mathbb{E}[\\varphi(X,c)].\\]\n\n\nThéorème 2.3 (Delta-méthode) Soit \\((X_n)\\) une suite de variables aléatoires réelles telle que \\(\\sqrt{n}(X_n - \\alpha)\\) converge en loi vers \\(N(0,\\sigma^2)\\). Pour toute fonction \\(g : \\mathbb{R} \\to \\mathbb{R}\\) dérivable en \\(\\alpha\\) (de dérivée non nulle en \\(\\alpha\\)), on a \\[ \\sqrt{n}(g(X_n) - g(\\alpha)) \\xrightarrow[n \\to \\infty]{\\text{loi}} N(0, g'(\\alpha)^2 \\sigma^2).\\]\n\nPlus généralement, si les \\(X_n\\) sont à valeurs dans \\(\\mathbb{R}^d\\) et que \\(\\sqrt{n}(X_n - \\alpha) \\to N(0,\\Sigma)\\), alors pour toute fonction \\(g:\\mathbb{R}^d \\to \\mathbb{R}^k\\) on a \\[ \\sqrt{n}(g(X_n) - g(\\alpha)) \\xrightarrow[n \\to \\infty]{\\text{loi}} N(0, Dg(\\alpha)\\Sigma Dg(\\alpha)^\\top)\\] où \\(Dg(x)\\) est la matrice jacobienne de \\(g\\) en \\(x\\)."
  },
  {
    "objectID": "ch3.html",
    "href": "ch3.html",
    "title": "3  Intervalles de confiance",
    "section": "",
    "text": "a"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Et après ?",
    "section": "",
    "text": "nasuitenasute"
  }
]