# Théorie des tests simples

\newcommand{\dtv}{\mathrm{d}_{\mathrm{TV}}}

## La distance en variation totale

Lorsqu'on cherche à tester une hypothèse de type $\text{loi} = P$ contre une hypothèse de type $\mathrm{loi} = Q$ (c'est-à-dire, deux hypothèses simples), on en revient à chercher un événément très improbable sous la loi $P$, et très probable sous la loi $Q$. On peut se demander en toute généralité quels sont les événements $A$ pour lesquels ces probabilités diffèrent le plus, c'est-à-dire les événements qui maximisent $P(A) - Q(A)$. Cela mène directement à la définition de la *variation totale*.   



:::{#def-dtv}


## distance en variation totale

Soient $P,Q$ deux mesures de probabilité sur un même espace $(\mathcal{X}, \mathscr{F})$. Leur distance en variation totale est 
$$ \dtv(P,Q) = \sup_{A \in \mathscr{F}}P(A) - Q(A). $$

:::


La distance en variation totale est un objet important en probabilités, qui possède de nombreuses propriétés. Parmi elles, 

1. C'est une distance sur l'espace des mesures de probabilité. 
2. Elle génère une topologie plus fine que celle de la convergence en loi ; autrement dit, si $\dtv(P_n, Q) \to 0$ alors $P_n$ converge en loi vers $Q$ mais l'inverse n'est pas vrai. 

:::{#prp-dtv}

Soit $\nu$ une mesure telle que $P$ et $Q$ sont absolument continues par rapport à $\nu$, de densités respectives $p$ et $q$ par rapport à $\nu$. Alors, 

$$\dtv(P,Q) = \int_{\mathcal{X}} (p(x) - q(x))_+d\nu = \frac{1}{2}\int_{\mathcal{X}} |p(x) - q(x)|d\nu.$$ {#eq-dtvformule}

De plus, notons $E$ l'ensemble mesurable $\{p(x)>q(x)\}$. Alors, 
$$\dtv(P,Q) = P(E) - Q(E).$${#eq-dtv-2}
:::

:::{.proof}

Pour tout événement $A \in \mathscr{F}$, la différence $P(A) - Q(A)$ est égale à $\int_A p(x) - q(x) d\nu$, qui peut elle-même s'écrire sous la forme $$\int_{A \cap E} p(x) - q(x) d\nu + \int_{A \cap \bar{E}} p(x) - q(x) d\nu.$$
Le second terme est négatif, puisque si $x \notin E$ alors $p(x)\leqslant q(x)$. Ainsi, $P(A) - Q(A)$ est plus petit que le premier terme, lequel est à son tour plus petit que $\int_E (p-q)d\nu = P(E) - Q(E)$. Cela montre directement @eq-dtv-2. Au passage, il est évident que 
$$\int_E (p(x)-q(x))d\nu = \int_{\mathcal{X}}(p(x) - q(x))_+ d\nu,  $$
ce qui montre la première égalité de @eq-dtvformule. La seconde égalité résulte de la première, puisque comme $p$ et $q$ sont des densités de probabilité, on a forcément $\int (p-q)_+ = \int(p-q)_-$. 

:::


## Meilleur test possible au sens de l'affinité


L'affinité d'un test est la somme de ses erreurs de première et seconde espèce : c'est la probabilité de « se tromper » en général, quelle que soit l'hypothèse. 

:::{#thm-affinity}

Soit $\mathfrak{T}$ l'ensemble des tests possibles de l'hypothèse $H_0 : P = P_0$ contre l'hypothèse alternative $H_1 : P = P_1$. Alors, le test possédant la meilleure affinité possible parmi tous les tests possibles vérifie
$$\inf_{T \in \mathfrak{T}}~\{\alpha_T + \beta_T \} = 1 - \dtv(P_0, P_1). $$
En particulier, le test optimal pour l'affinité est donné par la région de rejet
$$ \mathsf{rejeter}_\star = \{p(x) > q(x)\}.$$
:::

:::{.proof}
Soit $T$ n'importe quel test. Son affinité $P_1(\{T=0\}) + P_0(\{T=1\})$. En passant au complémentaire dans le second terme, on obtient $$1 - (P_0(\{T=0\}) - P_1(\{T=0\})). $$
Cette quantité est forcément plus petite que $1 - \dtv(P_0, P_1)$ par la définition même de la variation totale. De plus, cette borne est atteinte en choisissant le test $T$ donné dans l'énoncé, d'où l'égalité. 
:::


## Bornes sur la variation totale

Le théorème précédent semble donner au problème de la construction de tests une réponse définitive : il donne le test optimal au sens de l'affinité. C'est pourtant trompeur, car la construction de ce test nécessite le calcul de la distance en variation totale, laquelle peut être notoirement difficile. En pratique, on cherche plutôt à *borner* cette distance par d'autres quantités plus faciles à calculer. Parmi ces quantités, la *divergence de Kullback-Leibler* joue un rôle extrêmement important, notamment pour son lien avec le maximum de vraisemblance que nous verrons plus tard. 

\newcommand{\dkl}{\mathrm{d}_{\mathrm{KL}}}

:::{#def-dkl}

Soient $P$ et $Q$ deux mesures, $P$ étant absolument continue par rapport à $Q$. Alors, 

$$ \dkl(P \mid Q) = \int \ln \left(\frac{\mathrm{d}P}{\mathrm{d}Q}\right)dP. $$

:::

Cette quantité n'est pas une distance, et c'est pour cela qu'on l'appelle *divergence* et qu'on la note avec une barre plutôt qu'une virgule : elle n'est pas symétrique en général. Cependant, elle est toujours positive, et n'est nulle que si $P=Q$. 

:::{#thm-BH}

## Borne de Bretagnole-Huber-Pinsker

$$ \dtv(P,Q) \leqslant \sqrt{1 - e^{-\dkl(P \mid Q)}}.$${#eq-bh}

:::

Il est très facile de vérifier que $\sqrt{1-e^{-x}}\leqslant \sqrt{x}$ lorsque $x>0$. Ainsi, @eq-bh entraîne la borne plus simple $\dtv \leqslant \sqrt{\dkl}$. La borne *classique* de Pinsker dit qu'en fait, on a légèrement mieux, puisqu'en toute généralité $\dtv \leqslant \sqrt{\dkl/2}$. 

:::{.proof} 

À écrire. 

:::