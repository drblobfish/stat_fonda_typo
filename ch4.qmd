# Test d'hypothèse 

Si l'on essaie d'estimer le rendement $\mu$ d'un actif financier, on cherche implicitement à savoir si l'on va investir ou pas. Cette décision dépendra de notre estimation : pour faire simple, on peut considérer que si nous estimons que le rendement est positif ($\hat{\mu}>0$), alors il faut investir. Sinon, on n'investira pas. 

Les tests d'hypothèses visent à formaliser cela. Faire une *hypothèse* dans un modèle statistique $(\mathcal{X}, \mathscr{F}, (P_\theta)_{\theta \in \Theta_0})$, c'est supposer que $\theta$ appartient à une certaine région de $H_0 \subset \Theta$. Les *tests* visent à construire des procédures pour tester une hypothèse nulle, que l'on notera $H_0$, contre une hypothèse alternative, notée $H_1$. 



Dans le cadre ci-dessus, on peut se placer dans un modèle où les rendements sont $\mathscr{N}(\mu, \sigma^2)$. On veut tester l'hypothèse nulle $H_0 : \mu \in ]-\infty, 0]$ contre l'hypothèse alternative $H_1 : \mu \in ]0,+\infty[$. 

\newcommand{\rejet}{\mathsf{rejeter}}
\newcommand{\accept}{\mathsf{accepter}}


:::{#def-test}
Un test est un événement qui, s'il survient, nous incite à rejeter l'hypothèse nulle. Cet événement sera noté $\rejet$ et son complémentaire sera noté $\accept$. 

- L'erreur de première espèce est la probabilité de rejeter l'hypothèse nulle à tort : $\alpha = \sup_{\theta \in H_0}P_\theta(\rejet)$. Le **niveau d'un test** est $1-\alpha$. C'est la probabilité d'accepter l'hypothèse nulle à raison. 

- L'erreur de seconde espèce est la probabilité de ne pas rejeter l'hypothèse nulle, à tort : $\beta = \sup_{\theta \in H_1}P_\theta(\accept)$. La **puissance d'un test** est $1-\beta$. C'est la probabilité de « détecter » l'hypothèse alternative à raison. 
:::

Par « événement », on veut bien dire « un élément de $\mathscr{F}$ », c'est-à-dire qui n'est déterminé que par les observations et pas par $\theta$. 

Un des grands objectifs de la statistique mathématique est de construire des familles de tests qui, pour un niveau de confiance $1-\alpha$ fixé, ont la plus grande puissance possible. Comme on verra dans les exemples, le rôle des deux hypothèses n'est pas interchangeable. Maximiser le niveau et la puissance ne reviennent pas au même. Le choix des hypothèses $H_0$ et $H_1$ n'est pas anodin : l'hypothèse $H_0$ est une hypothèse que l'on cherche implicitement à réfuter. 


1. Si $\theta \in H_0$ quel qu'il soit, les probablités pour qu'un certain événement $\rejet$ sont infimes -- disons, 1%. 
2. Si cet événement arrive, par contraposée, on est amenés à rejeter l'hypothèse selon laquelle $\theta$ est dans $H_0$. 

C'est pour cela que les tests sont une forme de logique statistique. Le raisonnement de base une contraposée : en logique, $A \Rightarrow B$ est équivalent à $\neg B \Rightarrow \neg A$. En statistiques, on pourrait écrire $\theta \in H_0 \Rightarrow \accept$ (avec grande probabilité), donc $\rejet \Rightarrow \theta \notin H_0$ (probablement). 

## Exemples de tests gaussiens


## La notion de $p$-valeur

La construction d'un test dépend du niveau de risque $\alpha$. Si le niveau de risque acceptable est de plus en petit, alors l'événement $\rejet_\alpha$ devrait être de moins en moins probable. D'ailleurs, $\rejet_0 = \varnothing$ et $\accept_0 = \Omega$ : si l'on ne tolère aucun niveau de risque de première espèce, c'est qu'on ne veut pas rejeter l'hypothèse nulle. 

Très souvent, si $\alpha<\beta$, on a même 
$$\rejet_\alpha \subset \rejet_\beta.  $$

:::{#def-pval}

La $p$-valeur d'une famille croissante de tests est le plus petit niveau de risque qui nous amène à rejeter l'hypothèse nulle compte tenu des observations. Formellement, 
$$ p = \inf\{\alpha>0 : \rejet_\alpha\}.$$

C'est donc une statistique. 
:::

