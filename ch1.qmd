# Introduction



## Un modèle-jouet

On observe donc $x_1, \dotsc, x_n$ (avec $n=100$). Comment avoir une idée de la véritable valeur de $\mu$ ? Évidemment, la moyenne empirique 
$$\bar x_n = \frac{x_1+\dotsb + x_n}{n}$$
vient naturellement à l'esprit. On trouve $\bar{x}_n \approx 21,6$. Cette valeur est une *estimation* de $\mu$. On pourrait se demander à quel point cette estimation est précise ou, disons, essayer de quantifier l'erreur possible qu'on fait si l'on dit que $\mu$ est égal à 21,6. 

Comme on a supposé que les $x_i$ sont des réalisations d'une loi gaussienne $N(\mu, 1)$, alors on sait que $\bar{x}_n$ est la réalisation d'une loi $N(\mu, 1/n)$, ou encore que $\bar{x}_n - \mu$ est la réalisation d'une gaussienne centrée de variance $1/n$. Les lois gaussiennes sont bien connues ; par exemple, avec probabilité supérieure à 99%, une gaussienne $N(0, \sigma^2)$ est comprise entre les valeurs $-2,96\sigma$ et $2,96\sigma$. Autrement dit, il y a 99% de chances pour que le nombre $|\bar{x}-\mu|$, qui représente l'erreur d'estimation, soit plus petite que $2,96/\sqrt{n} = 2,96/10 \approx 0,3$. 

Ce dernier raisonnement peut être vu d'une autre façon. Dire que $\bar{x}_n$ et $\mu$ ne diffèrent pas de plus de $0,3$, c'est équivalent à dire que $\mu$ appartient à l'intervalle $[\bar{x} - 0,3, \bar{x} +0,3]$. En d'autres termes, avec une probabilité supérieure à 99%, le vrai paramètre $\mu$ se situe entre $21,3$ et $21,9$. Cela laisse tout de même une chance de 1% que le paramètre $\mu$ ne soit pas dans cette région. 

Il existe encore un autre point de vue sur ce problème. Dans ce problème, nous ne sommes pas forcément intéressés par la valeur exacte de $\mu$. Ce qui nous intéresse, c'est plutôt d'être sûrs que le prix de l'actif est inférieur à un certain seuil (de rentabilité, par exemple). Typiquement, si j'ai un budget de 22€ et que mon estimation donne $\bar{x} = 21,4$, je suis a priori rassuré ; mais avec quel niveau de certitude ? Le raisonnement ci-dessus implique que, compte tenu de ce que j'ai observé et si mon hypothèse (les $x_i$ sont gaussiennes) est vraie, alors j'ai moins de 1% de me tromper si j'affirme que $\mu$ est inférieur à 22. 

Supposons maintenant qu'un autre produit attire mon attention. Je dispose de moins d'observations, disons seulement $y_1, \dotsc, y_m$ avec $m=36$. On peut encore raisonnablement supposer que les $y_i$ sont des réalisations de lois gaussiennes $N(\nu, 1)$. Mon estimation de $\nu$ donne $\bar{y}  = 21,5$. Le prix de ce bien Y semble donc inférieur au prix du bien X. Mais est-ce vraiment sûr ? Par le même raisonnement que celui ci-dessus, je peux dire qu'il y a 99% de chances pour que $\nu$ et $\bar{y}$ ne diffèrent pas de plus de $2,96/\sqrt{m} \approx 3/6 = 0,5$, et donc que $\nu$ soit quelque part entre $21$ et $22$. L'arbitrage entre $\mu$ et $\nu$ n'est pas évident ! 

<!-- On peut donc s'essayer à un petit raisonnement par l'absurde. Supposons un moment que ces deux prix soient identiques, c'est-à-dire que $\mu=\nu$. Si c'était le cas, alors $\bar{x}-\bar{y}$ devrait être une réalisation d'une loi $N(0, s^2$) où $s^2 = 1/n+1/m \approx 0,038$. Ainsi, $\bar{x} - \bar{y}$ aurait eu 99% de chances de se trouver entre les valeurs $\pm 2,96 s = \pm 0,57$.  -->

L'objectif du cours de statistiques de quantifier l'incertitude. Comme dans les exemples donnés ci-dessus, c'est un ensemble de méthodes scientifiques qui s'appuient sur la théorie des probabilités ; dans ce cours, on fera des hypothèses sur le hasard qui est en jeu, et on en tirera des conséquences *probables*. Ce qui différencie la statistique mathématique des affirmations de votre tante Lise sur l'inflation, c'est que la statistique a pour objectif de quantifier les niveaux d'incertitude des énoncés que nous faisons. 

## Qu'est-ce qu'un problème statistique ?



Il n'y aurait pas de statistiques s'il n'y avait pas de monde réel, et comme chacun sait, le monde réel est principalement composé de quantités aléatoires. 

Un problème statistique tire donc toujours sa source d'un ensemble d'observations, disons $n$ observations notées $x_1, \dotsc, x_n$ ; cet ensemble d'observations est appelé un *échantillon*. L'hypothèse de base de tout travail statistique consiste à supposer que cet échantillon suit une certaine loi de probabilité ; l'objectif est de trouver laquelle. Évidemment, on ne va pas partir de rien : il faut bien faire des hypothèse minimales sur cette loi. Ce qu'on appelle un *modèle statistique* est le choix d'une famille de lois de probabilités que l'on suppose pertinentes. 

:::{#def-mst}

Formellement, choisir un modèle statistique revient à choisir trois choses : 

- $\mathcal{X}$, l'espace dans lequel vit notre échantillon ; 
- $\mathscr{F}$, une tribu sur $\mathcal{X}$, pour donner du sens à ce qui est observable ou non ; 
- $(P_\theta)_{\theta \in \Theta}$, une famille de mesures de probabilités sur $\mathcal{X}$ indexée par $\theta \in \Theta$, où $\Theta$ est appelé espace des paramètres.  

:::

En pratique, dans ce cours, on aura toujours un échantillon $(x_1, \dotsc, x_n)$ où les $x_i$ vivent dans un même espace, disons $\mathbb{R}^d$ pour simplifier. On devrait donc écrire $\mathcal{X} = \mathbb{R}^{d\times n}$ ; et l'on fera toujours l'hypothèse que ces observations sont indépendantes les unes des autres, et que ces observations ont la même loi de probabilité. Autrement dit, on se donnera toujours une mesure $\mu_\theta$ sur $\mathbb{R}^d$ et on supposera que la loi de notre échantillon est $P_\theta = \mu_\theta^{\otimes n}$. Dans ce cadre, les observations $x_i$ sont des *réalisations* de variables aléatoires iid de loi $\mu_\theta$. 


::: {#def-identifiable}

On dit qu'un modèle statistique est identifiable si $\theta \neq \theta'$ entraîne $P_\theta \neq P_{\theta'}$. 

:::


Si l'on a bien choisi notre modèle statistique, alors il existe un « vrai » paramètre, disons $\theta_\star$, tel que les observations $x_1, \dotsc, x_n$ sont des réalisations de loi $\mu_{\theta_\star}$. L'objectif est alors de trouver $\theta_\star$ ou quelque information que ce soit le concernant. 



  


Dans un modèle (identifiable), la statistique inférentielle (classique) permet de faire trois choses:

- Trouver une valeur approchée du vrai paramètre $\theta_\star$ (estimation ponctuelle).
- Donner une zone de $\Theta$ dans laquelle le vrai paramètre $\theta_\star$ a des chances de se trouver (intervalle de confiance).
-  Répondre à des questions binaires sur $\theta_\star$, par exemple « $\theta_\star$ est-il positif ? ».




## Qu'est-ce qu'un estimateur ?



:::{#def-stat}

Une *statistique* est une fonction mesurable des observations. Plus formellement, si le modèle statistique fixé est $(\mathcal{X}, \mathscr{F}, P)$, alors une statistique est n'importe quelle fonction mesurable de $(\mathcal{X}, \mathscr{F})$. 
::: 


Le point important est qu'une statistique ne peut pas prendre $\theta$ en argument. Ses valeurs ne doivent dépendre du paramètre $\theta$ qu'au travers de $P_\theta$. 


Si $X$ est une variable aléatoire et $T$ une statistique, alors $T(X)$ est une variable aléatoire. On peut donc définir des quantités théoriques liées à $T$: typiquement, si $X$ a pour loi $P_\theta$, on peut définir la valeur moyenne de $T$ sous le modèle $P_\theta$ comme 
$$\mathbb{E}_\theta[T(X)] = \int_{\mathcal{X}} T(x) P_\theta(dx)$$
ou encore sa variance $\mathbb{E}_\theta[\mathsf{t}(X)^2] - (\mathbb{E}_\theta[\mathsf{t}(X)])^2$, etc. On peut aussi calculer la valeur de cette statistique sur l'échantillon dont on dispose, c'est-à-dire $\mathsf{t}(x_1, \dotsc, x_n)$. Ce qui ne se voit pas dans la définition, c'est qu'une bonne statistique devrait être facilement calculable ; à la place de *statistique*, on peut penser à *algorithme* : une bonne statistique doit pouvoir être calculée facilement par un algorithme ne prenant en entrée que les échantillons $x_i$. 



Si le but est de deviner la valeur de $\theta$ à partir des observations, il est naturel de considérer des statistiques à valeurs dans $\Theta$. C'est précisément la définition d'un estimateur.

:::{#def-estimateur}
Dans le modèle $(\mathcal{X},\mathcal{A}, (P_\theta)_{\theta \in \Theta})$, un estimateur de $\theta$ est une statistique à valeurs dans $\Theta$.
:::

En fait, on n'est pas obligés de vouloir estimer précisément $\theta$. Peut-être qu'on veut estimer quelque chose qui dépend de $\theta$, mais qui n'est pas $\theta$ ; disons, une fonction $q(\theta)$. Dans ce cas, un estimateur de $q(\theta)$ sera simplement une statistique à valeurs dans l'espace où vit $q(\theta)$. 



## Non-paramétrique

Traditionnellement, on  distingue deux grands types de modèles : on dit qu'un modèle est *paramétrique* lorsque le paramètre $\theta$ vit dans un espace de dimension finie (autrement dit quand $\Theta$ est une partie de $\mathbb{R}^d$), et sinon on dit que le modèle est non-paramétrique. On verra quelques idées d'estimation non-paramétrique dans le dernier chapitre du cours. 


