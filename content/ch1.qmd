# Introduction

Les outils des statistiques furent créés pour analyser des phénomènes quantitatifs dans lesquels la présence de *bruit* ou de *hasard* rend l'analyse classique moins puissante. Il peut s'agir de problèmes dans lesquels des données indépendantes ont été générées par le même phénomène. Dans cette section, nous allons développer un exemple qui illustre bien les questions qui se posent et la façon de les résoudre, puis nous poserons quelques bases qui nous permettront d'utiliser le langage des mathématiques. 



## Une histoire d'influenceurs


Dans le monde des applications mobiles, une donnée clé pour de nombreux modèles de type freemium est la *conversion*. Il ne suffit pas que des utilisateurs téléchargent l'app et utilisent sa version gratuite : encore faut-il qu'ils décident de payer, c'est-à-dire de convertir leur accès gratuit en abonnement payant. C'est ce qu'on appelle « convertir ». À de nombreux égard, cette métrique est essentielle pour faire croître un projet. Or, avant même de *convertir* des utilisateurs, il est évidemment essentiel d'en *acquérir*. C'est le rôle du marketing ; aujourd'hui, une grande partie du marketing moderne passe par du marketing de contenu : on paie des influenceurs pour qu'ils parlent de l'app ou créent du « contenu » qui la mentionne. 

Lorsque j'ai lancé ma première app mobile, mon amie Carlita était influenceuse, et possédait une communauté assez large et proche de mon business. J'avais signé avec elle un contrat de marketing : Carlita devait publier une vingtaine de contenus par mois (stories, reels) parlant de mon app. C'était mon seul et unique canal d'acquisition de clients. 


**Estimation.** 
Entre janvier et mars, Carlita avait généré 4023 acquisitions, et sur ces acquisitions, il y eut 460 conversions. À supposer que la communauté de Carlita soit stable et qu'une proportion fixe $p$ des nouveaux utilisateurs convertissent effectivement le mois suivant, on pouvait donc estimer $p$ par $460/4023 \approx 11.5\%$. 

**Précision.** Au fil du temps, Carlita générait environ 10000 nouveaux utilisateurs gratuits par semestre. Je pouvais donc m'attendre à ce que dans la foulée, $11.5\% \times 10000 = 1150$ d'entre eux convertissent leur abonnement gratuit en abonnement payant, ce qui me permettait de prévoir tout un tas de choses (besoins en coût de serveurs, cashflow futur, etc). Seulement, pour des raisons comptables, il était indispensable que le nombre de conversions semestrielles ne tombe pas en dessous de 1000. À quel point ce nombre de 11.5\% était-il donc précis ? 

Une modélisation rapide permet de s'en rendre compte. Chaque utilisateur peut être vu comme une variable de Bernoulli de paramètre $p$ : $X_i=1$ si conversion, 0 sinon. L'estimation ci-dessus est la moyenne empirique des conversions, $\bar{X}_n = (X_1 + \dotsb + X_n) / n$ avec $n = 4023$. La loi de cette variable est tout simplement $\mathrm{Bin}(n,p)/n$, et on sait qu'avec probabilité supérieure à 99\%, l'estimée $\bar{X}_n$ et la vraie valeur $p$ ne diffèrent pas de plus de $0.7\%$ : l'inégalté de Bienaymé-Chebychev dit que $\mathbb{P}(|\bar{X}_n - p|>0.007) < \frac{\mathrm{Var}(\bar{X}_n)}{0.007^2}$, et l'on peut borner ceci (pourquoi ?) par 
$$\frac{1}{4n 0.007^2} = 99\%.$$
 Autrement dit, j'étais sûr à 99\% que le vrai taux de conversion de Carlita se situait quelque part entre 10.8\% et 12.2\%. En moyenne, il était donc peu probable que sur 10000 utilisateurs que Carlita pouvait emmener sur mon app chaque semestre, seulement moins de 1000 convertissent. 

Ce raisonnement donne ce qu'on appelle un *intervalle de confiance* pour $p$. 

**Tests.** Un jour, une webagence vint me démarcher. Elle me proposait de signer un contrat avec un de *ses* influenceurs, appelons-le Szeequie, qui avait un taux de conversion supposé meilleur que Carlita, à savoir 12\%. L'agence avait estimé ce chiffre sur le dernier mois de Szeequie : il avait généré 10000 acquisitions pour 1200 conversions, sur des apps similaires aux miennes. Évidemment, une question se pose : Szeequie a généré bien plus d'acquisitions que Carlita, l'estimation de 12\% est donc plus précise que celle des 11.5\%. Mais à quel point ? Peut-on *vraiment* dire que la communauté de Szeequie convertit mieux que celle de Carlita ? 

Reprenons le calcul ci-dessus. On a vu qu'il y a 99\% de chances pour que $p_{\mathrm{carlita}}$ soit compris entre 10.7\% et 12.2\%. Le même calcul montre qu'il y a 99\% de chances pour que $p_{\mathrm{szeequie}}$ soit compris entre 11.99\% et 12.01\%. 

Autrement dit, en écartant des événements trop rares (qui arrivent moins de 1\% des fois), les deux intervalles se chevauchent : je ne suis pas **absolument sûr** que Szeequie est absolument meilleur que Carlita. Peut-être que $p_{\mathrm{carlita}}$ est égal à 12.2\% mais qu'elle n'avait pas eu de chance lorsque j'ai fait ma première estimation. En revanche, si Carlita se met à acquérir pour moi beaucoup d'utilisateurs (disons, 100000) et que l'estimation de son taux de conversion ne change pas et reste 11.5\%, alors les deux estimations seront plus précises et me permettront d'être sûr que je devrais plutôt travailler avec Szeequie.

En attendant, Carlita reste mon amie : tant que je ne suis pas sûr que d'autres sont vraiment meilleurs, je préfère travailler avec elle. 

Ce mode de raisonnement porte le nom de *test d'hypothèse*, et ce n'est pas pour rien que je mentionne mon amitié avec Carlita : dans tous les problèmes statistiques, il y a des préférences, des non-dits et des choix qui rendent les choses non symétriques. On veut avant tout être sûr de rejeter une hypothèse (dite « nulle »), et surtout pas la rejeter à tort. 
<!--
## Un exemple pour fixer les idées


Une grande enseigne de distribution possède $n=100$ magasins identiques, qui génèrent chaque année un chiffre d'affaire annuel (CA, en millions d'euros). Ce chiffre oscille autour d'une valeur de référence $\mu$. Cette valeur n'est pas observée ; ce qui est observé, ce sont tous les chiffres d'affaires des $n$ magasins, qui fluctuent tous autour de la vraie valeur $\mu$. Ces fluctuations proviennent de nombreuses sources : erreurs comptables, perturbations des ventes dues aux fournisseurs ou aux prix, etc. Ce qu'on observe, c'est donc des chiffres $x_1, \dotsc, x_n$ qui ne sont pas tous égaux ; comment avoir une idée de la véritable valeur de $\mu$ ? 

**Estimation.** Évidemment, la moyenne empirique 
$$\bar x_n = \frac{x_1+\dotsb + x_n}{n}$$
vient naturellement à l'esprit. En faisant le calcul, on trouve $\bar{x}_n \approx 21,6$. Cette valeur est une *estimation* du CA moyen $\mu$. Ce chiffre peut être utilisé par l'enseigne, par exemple pour jauger la rentabilité d'un possible plan d'ouverture de nouveaux magasins. 

**Précision**. On pourrait se demander à quel point cette estimation est précise ou, disons, essayer de quantifier l'erreur possible qu'on fait si l'on dit que $\mu$ est égal à 21,6 millions d'euros. Cela nécessite de faire quelques hypothèses sur le hasard qui génère les fluctuations des $x_i$ autour de $\mu$. Ces fluctuations observées au cours de l'année proviennent de l'agrégation de toutes les fluctuations quotidiennes, lesquelles sont à peu près indépendantes, et pour cette raison on peut supposer (pour commencer) que ces fluctuations sont gaussiennes et ont à peu près la même variance, disons $\sigma^2=1$.  Comme on a supposé que les $x_i$ sont des réalisations d'une loi gaussienne $N(\mu, 1)$, alors on sait que $\bar{x}_n$ est la réalisation d'une loi $N(\mu, 1/n)$, ou encore que $\bar{x}_n - \mu$ est la réalisation d'une gaussienne centrée de variance $1/n$. Les lois gaussiennes sont bien connues ; par exemple, avec probabilité supérieure à 99%, une gaussienne $N(0, \sigma^2)$ est comprise entre les valeurs $-2,96\sigma$ et $2,96\sigma$. Autrement dit, il y a 99% de chances pour que le nombre $|\bar{x}-\mu|$, qui représente l'erreur d'estimation, soit plus petite que $2,96/\sqrt{n} = 2,96/10 \approx 0,3$. 

Ce dernier raisonnement peut être vu d'une autre façon. Dire que $\bar{x}_n$ et $\mu$ ne diffèrent pas de plus de $0,3$, c'est équivalent à dire que $\mu$ appartient à l'intervalle $[\bar{x} - 0,3, \bar{x} +0,3]$. En d'autres termes, avec une probabilité supérieure à 99%, le vrai CA $\mu$ de chaque magasin se situe entre $21,3$ et $21,9$. Cela laisse tout de même une chance de 1% que le paramètre $\mu$ ne soit pas dans cette région. 

**Tests**. Il existe encore un autre point de vue sur ce problème. Par exemple, le conseil d'administration de la firme veut s'assurer que le dirigeant a bien tenu sa promesse selon laquelle le CA de chaque magasin était supérieur à 21 millions d'euros. La valeur exacte de $\mu$ n'est pas le plus important : ce qui nous intéresse maintenant, c'est plutôt d'être sûrs que $\mu$ n'est pas inférieur au seuil de 21. Le dirigeant, fin statisticien, effectue alors un raisonnement par l'absurde *en probabilité*. Supposons que le CA $\mu$ soit effectivement égal à 21 (ou même, inférieur). Alors, par les mêmes calculs que ci-dessus, cela voudrait dire qu'avec 99% de chances, $\bar{x}_n$ et $21$ ne devraient pas différer de plus de $0,3$ ; autrement dit, que $\bar{x}_n$ devrait se situer entre $20,7$ et $21,3$. Ce n'est pas le cas, puisque $\bar{x}_n = 21,6$. Si $\mu$ est réellement plus petit que 21, alors ce qu'on a observé est extrêmement peu probable. Par contraposée probabiliste, il est raisonnable de rejeter l'hypothèse selon laquelle $\mu$ est inférieur à 21. 

---

Les trois points de vue donnés ci-dessus sont en quelque sorte les piliers de l'analyse statistique. L'estimation consiste à deviner une valeur cachée dans du bruit ; les intervalles de confiance consistent à donner une région dans laquelle se trouve cette valeur ; les tests d'hypothèse permettent de raisonner de façon logique sur cette valeur. 

:::{.deep}

L'objectif du cours de statistiques de quantifier l'incertitude liée au hasard dans chacun de ces objectifs. Comme dans les exemples donnés ci-dessus, c'est un ensemble de méthodes scientifiques qui s'appuient sur la théorie des probabilités ; dans ce cours, on fera des *hypothèses* sur le hasard qui est en jeu, et on en tirera des conséquences *probables* sur le modèle sous-jacent. En théorie des probabilités, le jeu est plutôt inverse : partant d'un modèle probabiliste fixé, on essaie de déterminer quel sera le comportement des réalisations de ce modèle. Il semble difficile de faire l'un sans l'autre. 
:::
-->

## Qu'est-ce qu'un problème statistique ?



Il n'y aurait pas de statistiques s'il n'y avait pas de monde réel, et comme chacun sait, le monde réel est principalement composé de quantités aléatoires. 

Un problème statistique tire donc toujours sa source d'un ensemble d'observations, disons $n$ observations notées $x_1, \dotsc, x_n$ ; cet ensemble d'observations est appelé un *échantillon*. L'hypothèse de base de tout travail statistique consiste à supposer que cet échantillon suit une certaine loi de probabilité ; l'objectif est de trouver laquelle. Évidemment, on ne va pas partir de rien : il faut bien faire des hypothèse minimales sur cette loi. Ce qu'on appelle un *modèle statistique* est le choix d'une famille de lois de probabilités que l'on suppose pertinentes. 

:::{#def-mst}

Formellement, choisir un modèle statistique revient à choisir trois choses : 

- $\mathcal{X}$, l'espace dans lequel vit notre échantillon ; 
- $\mathscr{F}$, une tribu sur $\mathcal{X}$, pour donner du sens à ce qui est observable ou non ; 
- $(P_\theta)_{\theta \in \Theta}$, une famille de mesures de probabilités sur $\mathcal{X}$ indexée par $\theta \in \Theta$, où $\Theta$ est appelé espace des paramètres. On écrira fréquemment $\mathbb{E}_\theta$ ou $\mathrm{Var}_\theta$ pour désigner des espérances, variances, etc., calculées avec la loi $P_\theta$. 

:::

En pratique, dans ce cours, on aura toujours un échantillon $(x_1, \dotsc, x_n)$ où les $x_i$ vivent dans un même espace, disons $\mathbb{R}^d$ pour simplifier. On devrait donc écrire $\mathcal{X} = \mathbb{R}^{d\times n}$ ; et l'on fera toujours l'hypothèse que ces observations sont indépendantes les unes des autres, et que ces observations ont la même loi de probabilité. Autrement dit, on se donnera toujours une mesure $p_\theta$ sur $\mathbb{R}^d$ et on supposera que la loi de notre échantillon est $P_\theta = p_\theta^{\otimes n}$. Dans ce cadre, les observations $x_i$ sont des *réalisations* de variables aléatoires $X_i$ iid de loi $p_\theta$. 

Il faut prendre garde à distinguer les variables aléatoires $X_i$, qui sont des objets théoriques, de leurs réalisations $x_i$, qui, elles, sont bel et bien observées. 


::: {#def-identifiable}

On dit qu'un modèle statistique est identifiable si $\theta \neq \theta'$ entraîne $P_\theta \neq P_{\theta'}$. 

:::


Si l'on a bien choisi notre modèle statistique, alors il existe un paramètre, disons $\theta_\star$, tel que les observations $x_1, \dotsc, x_n$ sont des réalisations de loi $p_{\theta_{\star}}$. Si ce n'est pas le cas, il existe certainement un $\theta_\star$ tel que $p_{\theta_\star}$ est « la loi la plus proche possible » de la vrai loi qui a généré les $x_i$. L'objectif est alors de trouver $\theta_\star$ ou quelque information que ce soit le concernant. 



  


Dans un modèle identifiable, la statistique inférentielle (classique) permet de faire trois choses :

- Trouver une valeur approchée du vrai paramètre $\theta_\star$ (estimation ponctuelle).
- Donner une zone de $\Theta$ dans laquelle le vrai paramètre $\theta_\star$ a des chances de se trouver (intervalle de confiance).
-  Répondre à des questions binaires sur $\theta_\star$, par exemple « $\theta_\star$ est-il positif ? ».




## Qu'est-ce qu'un estimateur ?



:::{#def-stat}

Une *statistique* est une fonction mesurable des observations. Plus formellement, si le modèle statistique fixé est $(\mathcal{X}, \mathscr{F}, P)$, alors une statistique est une fonction mesurable de $(\mathcal{X}, \mathscr{F})$. 
::: 


1) Le premier point important est qu'une statistique ne peut pas prendre $\theta$ en argument. Ses valeurs ne doivent dépendre du paramètre $\theta$ qu'au travers de $P_\theta$. 

2) Le second point important est que, si $X$ est une variable aléatoire et $T$ une statistique, alors $T(X)$ est une variable aléatoire. On peut donc définir des quantités théoriques liées à $T$: typiquement, si $X$ a pour loi $P_\theta$, on peut définir la valeur moyenne de $T$ sous le modèle $P_\theta$ comme 
$$\mathbb{E}_\theta[T(X)] = \int_{\mathcal{X}} T(x) P_\theta(dx)$$
ou encore sa variance $\mathbb{E}_\theta[T(X)^2] - (\mathbb{E}_\theta[T(X)])^2$, etc. On peut aussi calculer la valeur de cette statistique sur l'échantillon dont on dispose, c'est-à-dire $T(x_1, \dotsc, x_n)$. Par exemple, la moyenne empirique d'un $n$-échantillon réel est la fonction $T : (a_1, \dots, a_n) \to n^{-1}(a_1+\dotsb + a_n)$. Si les $x_i$ sont des réalisations des variables aléatoires $X_i$, alors $T(x_1, \dotsc, x_n)$ est une réalisation de la variable aléatoire $T(X_1, \dotsc, X_n)$. 

1) Ce qui ne se voit pas dans la définition, c'est qu'une bonne statistique devrait être facilement calculable ; à la place de *statistique*, on peut penser à *algorithme* : une bonne statistique doit pouvoir être calculée *facilement* par un algorithme ne prenant en entrée que les échantillons $x_i$. Si le calcul de la statistique nécessite seulement des multiplications et des additions (comme pour une moyenne empirique), c'est bien ; mais parfois, elle nécessite la résolution d'un problème algorithmique trop difficile (typiquement NP-complet).  



Si le but est de deviner la valeur de $\theta$ à partir des observations, il est naturel de considérer des statistiques à valeurs dans $\Theta$. C'est précisément la définition d'un estimateur.

:::{#def-estimateur}
Dans le modèle $(\mathcal{X},\mathcal{A}, (P_\theta)_{\theta \in \Theta})$, un estimateur de $\theta$ est une statistique à valeurs dans $\Theta$.
:::

En fait, on n'est pas obligés de vouloir estimer précisément $\theta$. Peut-être qu'on veut estimer quelque chose qui dépend de $\theta$, mais qui n'est pas $\theta$, comme $\cos(\theta)$ ou $\theta^2$ ; disons, une fonction $\varphi(\theta)$. Dans ce cas, un estimateur de $\varphi(\theta)$ sera simplement une statistique à valeurs dans l'espace où vit $\varphi(\theta)$. 



## Points de vue

**Inférence paramétrique.** La plupart des expériences/modèles statistiques que nous rencontrerons dans ce cours, seront de nature dite *paramétrique*, autrement dit indexés par des parties de $\mathbb{R}^d$. Le mot "paramètre" est en lui-même trompeur : on parle souvent de paramètre d'une distribution pour désigner ce qui devrait plutôt s'appeler une fonctionnelle. Par exemple, la moyenne, la covariance  d'une   distribution sur $\mathbb{R}^d$ sont des paramètres de cette distribution. Les quantiles, l'asymétrie, la kurtosis sont d'autres paramètres.

**Statistique non paramétrique.** Tous les modèles ne sont pas paramétriques au sens ci-dessus : dans de nombreux développements des statistiques, par exemple en estimation de densité, on travaille sur des modèles plus riches qui n'admettent pas de paramétrisation naturelle par une partie d'un espace euclidien de dimension finie. C'est ce qu'on appelle l' *estimation non-paramétrique*. Nous y reviendrons au dernier chapitre. 


**Statistique bayésienne.** En statistique paramétrique, les paramètres $\theta$ déterminent le hasard qui génère les observations $x_i$. La statistique bayésienne consiste à renverser le point de vue, et à rendre le paramètre $\theta$ lui-même aléatoire ; sa loi, appelée *prior*, mesure "le degré de connaissance a priori" qu'on en a. La règle de Bayes explique comment cette loi est modifiée par les observations. C'est un point de vue qui ne sera pas abordé dans ce cours. 


